# Data Science Portfolio
## Courseworks from my Master's Degree
Name: Lee Kean Lim \
Program Title: MSc in Data Science and Business Analytics \
University: Asia Pacific University of Technology and Innovation \
Award: Distinction \
CGPA: 3.84 \
Program Duration: December 2021 to December 2022 \
Email: KeanLim.lee28@gmail.com

This repository archived the courseworks completed during my Master's Degree. The following provides a description of the coursework completed and skill set utilized. 

Date updated: 22-March-2022

---

# Table of Contents
1.0 Predictive Modeling\
[1.1 ABAV - Advanced Business Analytics and Visualization](#anchor1.1)
- Improving Banking Customer Retention by Customer Churn Prediction
1.2 DAP - Data Analytical Programming
- Automation of Loan Aproval Process Using SAS Programming
1.3 ML - Machine Learning
- E-Commerce Package Delivery Time Prediction Using Machine Learning


---

## 1.0 Predictive Modeling
**<a name="anchor1.1"></a>1.1 ABAV - Advanced Business Analytics and Visualization**
- **Title:** Improving Banking Customer Retention by Customer Churn Prediction
- **Description:** This study aims to improve banking customer retention by predicting churcn. The study will use a banking dataset retrieved from Kaggle and SAS Enterprise Miner to develop predictive models and identify causes of churn. The objective is to provide suggestions for reducing churn rate and improving customer relationship management.
- **Approach:** The work involves using machine learning to develop a predictive model for a dataset containing categorical and numerical variables. The dataset is split into training and testing data, explored through visualization and statistics, modified by encoding categorical variables and removing irrelevant features, and then used to develop two predictive models using logistic regression and artificial neural networks.
- **Result:** Suggestions were made to increase customer retention, such as knowing your customers through surveys and increasing customer satisfaction through on-premises services and customer engagement.
- **Skills:** SAS Enterprise Miner, Tableau, Statistics, Data Ingestion, Data Preprocessing, Data Visualization, Data Analysis, Machine Learning


**1.2 DAP - Data Analytical Programming** 
- **Title:** Automation of Loan Approval Process Using SAS Programming
- **Description:** This study aims to demonstrate the development of a loan approval prediction model using logistic regression and SAS programming. The loan approval process is being automated to improve speed and accuracy, with the aim of enhancing customer retention rate and experience.
- **Approach:** SAS programming was utilized to develop the automated loan approval program, which included descriptive analytics to identify data trends and quality issues. The logistic regression algorithm was used to develop the prediction model, providing probability outputs for increased interpretability. Finally, the program automatically generates a report for each applicant using the output delivery system.
- **Result:** The program significantly accelerated the loan approval process, improving efficiency and productivity.
- **Skills:** SQL, SAS Studio, Statistics, Data Ingestion, Data Preprocessing, Data Visualization, Data Analysis, Machine Learning


**1.3 ML - Machine Learning** 
- **Title:** E-Commerce Package Delivery Time Prediction Using Machine Learning
- **Description:** This study aims to develop prediction models using machine learning algorithms to predict the last-mile delivery time of shipping products as a classification problem of whether they are delivered on time or not. The objectives are to identify suitable algorithms, develop prediction models with hyperparameter optimization, and evaluate their performance against related works.
- **Approach:** The dataset used in this study is an e-commerce shipment dataset with 10999 observations and 12 variables. Four machine learning algorithms, including logistic regression, XGBoost, random forest, and AdaBoost, are used for prediction models. Evaluation metrics, such as confusion matrix, accuracy, specificity, sensitivity, ROC, and Cohen's kappa, are used to measure the performance of the models. The exploratory data analysis and data pre-processing steps were performed, including identifying missing values, dropping and recoding features, factoring categorical variables, feature encoding, feature scaling, and train-test data splitting for model fitting and validation.
- **Result:** The optimized AdaBoost model outperformed other models in this study and previous literature, achieving the highest accuracy of 69.82%. 
- **Skills:** R, Machine Learning, Data Preprocessing, Data Visualization, Data Analysis, Statistics, Hyperparameter Tuning, Model Evaluation


**1.4 DL - Deep Learning**
- **Title:** Concrete Surface Crack Detection by Deep Learning
- **Description:** This study aims to develop an image classifier using deep learning to detect the presence of concrete cracks on images. The problem is that public image datasets available for such study are often produced in a laboratory setting, not reflecting realistic jobsite conditions. The objective is to introduce noise to the dataset to simulate photos taken on a jobsite condition.
- **Approach:** Using a dataset of 40,000 images with equal representation of cracked and non-cracked surfaces. The dataset is preprocessed through noise introduction, resizing, and pixel normalization, with the experiments focusing on the impact of noisy data on model performance. A simple CNN architecture with three convolutional layers and global average pooling is utilized, with learning rate and epochs as the main hyperparameters, and the models are evaluated using accuracy, recall, and precision metrics.
- **Result:** A robust image classifier for concrete structural crack detection using data augmentation with noisy images were developed, achieving an accuracy of 99.22%, precision of 99.47%, and recall of 98.96%. The findings demonstrate that the integration of data augmentation improves the classifier's performance, making it suitable for real-world applications in structural inspection. A simple three-layer convolutional neural network (CNN) architecture was sufficient to provide high accuracy results, comparable to deeper architectures.
- **Skills:** Python, Deep Learning, Image Data, Image Data Augmentation, Image Preprocessing, Hyperparameter Tuning, Data Visualization, Data Analysis, Model Evaluation


**1.5 CP - Capstone**
- **Title:** Forex Market Price Prediction Using Multi-Time Series Analysis With Deep Learning
- **Description:** This study aims to design and develop a Forex price prediction model using deep learning techniques and multiple time series to produce highly accurate predictions of the next trading day's closing price. The objectives are to identify and implement suitable data preprocessing, design and develop price prediction models using deep learning algorithms and multiple timeframes, investigate and compare the predicted outputs with a baseline model, and evaluate the performance of the developed prediction models. Three different RNN-based models are developed, namely GRU, LSTM, and a feedforward neural network.
- **Approach:** The dataset is split into training, validation, and testing sets and segmented into seven timeframes. The sliding window method is used to represent the dataset for prediction, and hyperparameter tuning is performed for the GRU and LSTM models. Finally, the predicted outputs from the best performing models are combined using a feedforward neural network to produce the final prediction outcome.
- **Result:** The study compared the performance of LSTM-based and GRU-based models for Forex price prediction using different combinations of multiple timeframes. The results showed that the GRU-based models outperformed the LSTM-based models and that using two timeframes as predictors produced better results than using three timeframes. However, all models struggled to accurately predict price peaks and troughs during highly volatile market conditions. Proper selection of timeframe combinations is crucial for high prediction accuracy.
- **Skills:** Python, Deep Learning, Time Series Data, Data Preprocessing, Data Visualization, Data Analysis, Hyperparameter Tuning, Model Evaluation

---
## 2.0 Big Data & Cloud Computing
**2.1 BDAT - Big Data Analytics and Technologies**
- **Title:** Big Data Tools Proposal in Tourism
- **Description:** This study discusses the potential of using Big Data in the tourism sector to support decision making and increase profits. It outlines the challenges faced in implementing Big Data solutions and proposes a Big Data ecosystem to predict hotel and flight search trends in a faster and cheaper manner. The aim is to derive strategic value from Big Data in the tourism sector.
- **Approach:** Proposed a Big Data ecosystem for the company using various tools such as Hadoop Distributed File System, MongoDB, Spark, and more. Security measures such as implementing a security layer, data authorization, and accessibility are suggested to ensure the security and confidentiality of customer data.
- **Skills:** Understanding of Big Data Technologies, implementation and limitations.

**2.2 CIS - Cloud Infrastructures and Computing**
- **Title:** Review of Cloud Computing Impact on Sustainable Development
- **Description:** This study discusses the impact of cloud computing on the environment and the need for sustainability in the digital transformation era. The aim is to assess the green initiatives of cloud service providers and promote sustainable development. The objective is to reduce the negative impact of cloud computing on the environment and achieve a healthy, fair, and sustainable future.
- **Result:** The resource pooling, rapid elasticity, and broad network access features of cloud computing contribute to sustainable development by reducing the reliance on physical infrastructures, providing cost-effective measures to handle temporary excess workload, and reducing emissions from transportation. Cloud service providers such as Amazon, Microsoft, and Google have implemented various strategies to achieve environmental sustainability, including the adoption of renewable energy, improving power and water usage efficiency, and using innovative server cooling methods.
- **Skills:** Cloud computing

**2.3 CIS - Cloud Infrastructures and Computing**
- **Title:** Case Study: GoGreen Insurance Company Cloud Adoption
- **Description:** This case study outlines the cloud adoption plan for GoGreen Insurance Company. The aim is to improve the company's flexibility, performance, and security while also reducing costs. The objectives include implementing a scalable and reliable architecture, securing the network and data, and utilizing cost-effective services. The study covers details on network architecture, security, encryption, instance details, recovery point objectives, document storage, web, application, and database tiers, additional services, proposed architecture diagram, and cost considerations.
- **Approach:** The approach taken is to implement a cloud-based architecture using Amazon Web Services (AWS) to improve the company's flexibility, performance, and security while also reducing costs. The plan includes utilizing AWS services such as Auto Scaling, CloudWatch, and Route 53 to monitor and optimize resources and implementing security measures such as security groups and encryption to protect data.
- **Skills:** Cloud Computing, AWS, VPN, EC2, S3

---
## 3.0 Business Intelligence and Data Management
**3.1 DM - Data Management**
- **Title:** Data Pre-Processing & Data Exploration
- **Description:** This study aims to perform data pre-processing and exploratory data analysis on a loan dataset to improve the accuracy of machine learning models in loan prediction tasks.
- **Approach:** The approach utilized in this study include identifying and imputing missing values, removing outliers, and identifying relationships between variables. The hypotheses include relationships between income, gender, education level, repayment history, housing location, and marital status with loan approval.
- **Result:** The hypotheses formulated in the study were validated or invalidated based on graphical and numerical examination of the dataset. Results indicate that higher income results in a higher loan amount, applicants with higher education have a higher income, good repayment history increases loan approval rate, married applicants have a higher loan approval rate. However, the hypothesis that male applicants have a higher income and that housing price in urban areas is higher than semi-urban and rural areas were invalidated.
- **Skills:** SQL, SAS Studio, Data Preprocessing, Data Visualization, Data Analysis

**3.2 DM - Data Management**
- **Title:** Feature Engineering
- **Description:** The aim of this study is to prepare a loan dataset for machine learning predictive models by performing feature encoding and feature scaling. The problem addressed is the need for efficient and cost-effective loan approval processes in the banking sector. The objectives are to identify appropriate feature encoding and scaling methods and apply them to the dataset.
- **Approach:** This study outlines the process of importing and exporting a loan dataset in SAS Studio, and performing feature engineering techniques including feature encoding and feature scaling. The study uses one-hot encoding and min-max scaler methods, which are commonly used in loan dataset feature engineering.
- **Skills:** SQL, SAS Studio, Date Preprocessing, Data Visualization

**3.3 BIS - Business Intelligence Systems**
- **Title:** Improving Sales Performance of Women's Off-Road Bike
- **Description:** Global Bike Incorporated is a high-performance bicycle company that sells their products exclusively through a network of selected dealers. The sales department of GBI is chosen as a pilot run to investigate the reasons for low sales performance in the women's off-road bike (WORB), and propose sales strategies to improve its performance. The aim of the study is to propose strategies to improve the sales performance of the WORB, and the objectives are to identify the reasons for low sales performance and propose strategies to improve it.
- **Approach:** The analysis performed focused on identifying the reasons for the low sales performance of the WORB bicycle model in the US market. OLAP analytics were used to explore the data and external sources were mined to analyze information. The investigation found that seasonality, pricing, and location were not the issue causing low sales. External sources identified that the lack of support for female ridership in the sport of off-road biking may be a contributing factor.
- **Result:** Four recommendations were formulated to increase sales performance, which include organizing women's only events, employing female staff, active media posting about women's off-road biking, and designing women's specific biking gear.
- **Skills:** SAP Lumira, Business intelligence, Data Analysis, Data Visualization, OLAP, ETL

---
## 4.0 Natural Language Processing
**4.1 NLP - Natural Language Processing**
- **Title:** Spelling Checker Application
- **Description:** The design of a spelling error checker that can detect both non-word and real-word errors in English language text, with a focus on the domain of sciences. The aim is to facilitate the efficiency of English language users by providing suggestions for correction. The problem statement is the prevalence of spelling errors in written text, and the objective is to design a user-friendly interface that can detect and suggest corrections for both types of errors.
- **Approach:** The application consist of a backend and frontend. The backend includes a non-word model for detecting non-word errors and a real-word model for detecting and correcting syntax and semantics errors. The frontend includes a graphical user interface that integrates both models to enable users to check and correct spelling errors. Python packagse and libraries, as well as a training corpus, were utilized in the development of the system.
- **Result:** The evaluation results show an average accuracy of 79.81% and 83.37% for non-word and real-word error detection, respectively.
- **Skills:** Python, NLP, Machine Learning, Transformer
